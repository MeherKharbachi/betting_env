# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_betting_env.ipynb.

# %% auto 0
__all__ = ['module_path', 'BettingEnv']

# %% ../nbs/00_betting_env.ipynb 3
import pandas as pd
import warnings
import gym
import numpy
import numexpr
import json
import os
import sys

module_path = os.path.abspath(os.path.join(".."))
if module_path not in sys.path:
    sys.path.append(module_path)
from .asian_handicap_pnl import *
from .datastructure.odds import MarketOdds
from .config.mongo import mongo_init
from pymatchpred.datastructure.lineup import TeamSheet
from infi.traceback import pretty_traceback_and_exit_decorator
from pandas.core.common import SettingWithCopyWarning

warnings.simplefilter(action="ignore", category=SettingWithCopyWarning)

# %% ../nbs/00_betting_env.ipynb 6
class BettingEnv(gym.Env):
    """Base class for sports betting environments.

    Creates an OpenAI Gym environment that supports betting a (small / medium / large) amount
    on a single outcome for a single game.

    Parameters
    ----------
    observation_space : gym.spaces.Box
        The observation space for the environment.
        The observation space shape is (1, N) where N is the number of possible
        outcomes for the game + len(gameId, 2 lineups, ah line) .

    action_space : gym.spaces.Discrete
        The action space for the environment.
        The action space is a set of choices that the agent can do.

    balance : float
        The current balance of the environment.

    starting_bank : int, default=100
        The starting bank / balance for the environment.
    """

    metadata = {"render.modes": ["human"]}
    # actions
    ACTIONS_LIST = [
        [0, 0, 0, 0, 0],  # no bets
        [1, 0, 0, 0, 0],  # betting on home team (1x2)
        [0, 0, 1, 0, 0],  # betting on away team (1x2)
        [0, 1, 0, 0, 0],  # betting on draw (1x2)
        [0, 0, 0, 1, 0],  # betting on home (Asian Handicap)
        [0, 0, 0, 0, 1],  # betting on away (Asian Handicap)
    ]

    def __init__(
        self,
        game_odds,
        odds_column_names=[
            "preGameOdds1",
            "preGameOdds2",
            "preGameOddsX",
            "preGameAhHome",
            "preGameAhAway",
        ],
        bet_size=[0.05, 0.4, 0.7],
        starting_bank=100,
    ):
        """Initializes a new environment

        Parameters
        ----------
        game_odds: pandas dataframe
            A list of games, with their betting odds.
        odds_column_names: list of str
            A list of column names with length == number of odds.
        bet_size: list
            3 possible bets : small, medium and large
        starting_bank: int
            bank account

        """

        super().__init__()
        # games df
        self._game = game_odds.copy()
        # sort data by date
        if "gameDate" in self._game.columns:
            self._game["gameDate"] = pd.to_datetime(self._game["gameDate"])
            self._game = self._game.sort_values(by="gameDate")
        # odds columns names
        self._odds_columns_names = odds_column_names
        # odds (1X2 and Asian handicap) values
        self._odds = self._game[self._odds_columns_names].values
        # results
        self._results = self._game["result"].values
        # ah lines
        self._lines = self._game["lineId"].values
        # game goal-difference
        self._gd = self._game["postGameGd"].values
        # teams names
        self._teams = self._game[["homeTeamName", "awayTeamName"]]
        # teams lineups
        self._lineups = self._game[["homeTeamLineup", "awayTeamLineup"]].values
        # games ids
        self._game_ids = self._game["gameId"]
        # bet size
        self.bet_size = bet_size  # small bet, medium bet, large bet
        # observation space
        self.observation_space = gym.spaces.Box(
            low=1.0,
            high=float("Inf"),
            shape=(1, (self._odds.shape[1] + 4)),
            dtype=numpy.float64,
        )
        # actions space
        self.action_space = gym.spaces.Tuple(
            (
                gym.spaces.Discrete(len(BettingEnv.ACTIONS_LIST)),  # betting action
                gym.spaces.Discrete(
                    len(self.bet_size)
                ),  # betting small or medium or large bet for the chosen action
            )
        )
        # env balance
        self.balance = self.starting_bank = starting_bank
        # current step (game)
        self.current_step = 0
        # bet size for each outcome
        self.bet_size_matrix = None

    def _get_current_index(self):
        return self.current_step % self._odds.shape[0]

    def get_odds(self):
        """Returns the odds for the current step.

        Returns
        -------
        odds : numpy.ndarray of shape (1, n_odds)
            The odds for the current step.
        """
        return pd.DataFrame([self._odds[self.current_step]]).values

    def get_bet(self, action):
        """Returns the betting matrix for the action provided.

        Parameters
        ----------
        action : int
            An action provided by the agent.

        Returns
        -------
        bet : array of shape (1, n_odds)
            The betting matrix, where each outcome specified in the action
            has a value of 1 and 0 otherwise.
        """
        return BettingEnv.ACTIONS_LIST[action[0]]

    def get_bet_size(self, action):
        """Returns bet size for the action provided.

        Parameters
        ----------
        action : int
            An action provided by the agent.

        Returns
        -------
        bet_size : array of shape (1, n_odds)
            The betting size matrix, where each outcome specified in the action
            has the chosen value by the agent.
        """
        # binary bets
        bet_size_matrix = numpy.zeros(shape=(1, self._odds.shape[1]))
        # if the agent wants to bet
        if action[0] != 0:
            # bet value
            size_bet = self.bet_size[action[1]] * self.balance
            # on which outcome the agent will bet
            bet_index = numpy.where(
                numpy.array(BettingEnv.ACTIONS_LIST[action[0]]) == 1
            )
            # assign bet value to the chosen outcome
            bet_size_matrix[:, bet_index] = bet_size_matrix[:, bet_index] + size_bet

        return bet_size_matrix

    @pretty_traceback_and_exit_decorator
    def step(self, action):
        """Run one timestep of the environment's dynamics. When end of episode is reached,
        you are responsible for calling reset() to reset this environment's state.

        Accepts an action and returns a tuple (observation, reward, done, info).

        Parameters
        ----------
        action : int
            An action provided by the agent.

        Returns
        -------
        observation : dataframe
            The agent's observation of the current environment
        reward : float
            The amount of reward returned after previous action
        done : bool
            Whether the episode has ended, in which case further step() calls will return undefined results
        info : dict
            Contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)

        """
        # current odds
        odds = self.get_odds()
        # reward
        reward = 0
        # finish
        done = False
        # episode info
        info = self.create_info(action)
        # bet size
        self.bet_size_matrix = self.get_bet_size(action)

        if self.balance < 1:  # no more money
            done = True
        else:
            # bet action
            bet = self.get_bet(action)
            # game result
            results = self.get_results()
            if self.legal_bet(bet):  # making sure agent has enough money for the bet
                # reward (positive or negative)
                reward = self.get_reward(bet, odds, results)
                # update balance
                self.balance += reward
                info.update(legal_bet=True)
            else:
                reward = -(bet * self.bet_size_matrix).sum()
            # update info
            info.update(results=results.argmax())
            info.update(reward=reward)
            # get the current observation
            obs = self.get_observation()
            # increment step
            self.current_step += 1
            # check if we are finished
            if self.finish():
                done = True
        # update flag
        info.update(done=done)
        # return
        return obs, reward, done, info

    def get_observation(self):
        """return the observation of the current step.

        Returns
        -------
        obs : numpy.ndarray of shape (1, n_odds + 4)
            The observation of the current step.
        """
        # current game
        index = self._get_current_index()
        # current game id
        game_id = self._game_ids[index]
        # current game lineups
        lineups = self._lineups[index]
        # chosen odds
        betting_market = self.get_odds()
        betting_market_1X2 = betting_market[:, 0:3]
        betting_market_ah = betting_market[:, 3:]
        # chosen line (AH line)
        line = self._lines[index]
        # the observation
        obs = {
            "gameId": game_id,
            "home_lineup": lineups[0],
            "away_lineup": lineups[1],
            "odds_1": betting_market_1X2[0][0],
            "odds_X": betting_market_1X2[0][1],
            "odds_2": betting_market_1X2[0][2],
            "line": line,
            "odds_ah_home": betting_market_ah[0][0],
            "odds_ah_away": betting_market_ah[0][1],
        }
        return pd.DataFrame(obs, index=[0]).values

    def get_reward(self, bet, odds, results):
        """Calculates the reward

        Parameters
        ----------
        bet : array of shape (1, n_odds)
        odds: dataframe of shape (1, n_odds)
            A games with its betting odds.
        results : array of shape (1, n_odds)

        Returns
        -------
        reward : float
            The amount of reward returned after previous action
        """
        # agent choice
        bet_index = numpy.argmax(numpy.array(bet))
        # bet size
        bet_size_matrix = self.bet_size_matrix
        # if the action is a AH bet
        if bet_index in [3, 4]:
            # game goal_difference
            obs_gd = (
                self._gd[self.current_step]
                if bet_index == 3
                else -self._gd[self.current_step]
            )
            # ah line
            ah_line = float(
                self._lines[self.current_step]
                if bet_index == 3
                else -self._lines[self.current_step]
            )
            # ah side odds
            ah_odds = (
                odds[:, 3:4][0].item() if bet_index == 3 else odds[:, 4:][0].item()
            )
            # calculate profit
            profit = AsianHandicap.pnl(obs_gd, ah_line, ah_odds)
            profit = (
                0
                if profit is None
                else numexpr.evaluate("sum(bet_size_matrix * profit)")
            )
        else:  # case 1X2
            reward = numexpr.evaluate("sum(bet * bet_size_matrix * results * odds)")
            expense = numexpr.evaluate("sum(bet * bet_size_matrix)")
            profit = reward - expense

        return profit

    def reset(self):
        """Resets the state of the environment and returns an initial observation.

        Returns
        -------
        observation : dataframe
            the initial observation.
        """
        self.balance = self.starting_bank
        self.current_step = 0
        return self.get_observation()

    def render(self, mode="human"):
        """Outputs the current balance and the current step.

        Returns
        -------
        msg : str
            A string with the current balance,
            the current step and the current game info.
        """
        index = self._get_current_index()
        teams = self._teams.iloc[index]
        game_id = self._game_ids[index]
        teams = teams.itertuples() if isinstance(teams, pd.DataFrame) else [teams]
        teams_str = ", ".join(
            [
                "Home Team: {} VS Away Team: {}".format(
                    row.homeTeamName, row.awayTeamName
                )
                for row in teams
            ]
        )

        print("Current balance at step {}: {}".format(self.current_step, self.balance))
        print("Current game id : {}".format(game_id))
        print(teams_str)

    def finish(self):
        """Checks if the episode has reached an end.

        The episode has reached an end if there are no more games to bet.

        Returns
        -------
        finish : bool
            True if the current_step is equal to n_games, False otherwise
        """
        return self.current_step == self._odds.shape[0]  # no more games left to bet

    def get_results(self):
        """Returns the results matrix for the current step.

        Returns
        -------
        result : array of shape (1, n_odds)
            The result matrix, where the index of the outcome that happened
            value is 1 and the rest of the indexes values are 0.
        """
        result = numpy.zeros(shape=(1, self._odds.shape[1]))
        result[
            numpy.arange(result.shape[0], dtype=numpy.int32),
            numpy.array([self._results[self.current_step]], dtype=numpy.int32),
        ] = 1

        return result

    def legal_bet(self, bet):
        """Checks if the bet is legal.

        Checks that the bet does not exceed the current balance.

        Parameters
        ----------
        bet : array of shape (1, n_odds)
            The bet to check.

        Returns
        -------
        legal : bool
            True if the bet is legal, False otherwise.
        """
        return (bet * self.bet_size_matrix).sum() <= self.balance

    def create_info(self, action):
        """Creates the info dictionary for the given action.

        The info dictionary holds the following information:
            * the current step
            * game odds of the current step
            * bet action of the current step
            * bet size of the current step
            * the balance at the start of the current step
            * reward of the current step
            * game result of the current step
            * state of the current step
        Parameters
        ----------
        action : int
            An action provided by the agent.

        Returns
        -------
        info : dict
            The info dictionary.
        """
        return {
            "current_step": self.current_step,
            "odds": self.get_odds(),
            "bet_action": env.ACTIONS_LIST[action[0]],
            "bet_size": self.bet_size[action[1]],
            "balance": self.balance,
            "reward": 0,
            "legal_bet": False,
            "results": None,
            "done": False,
        }
